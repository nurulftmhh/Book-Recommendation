# -*- coding: utf-8 -*-
"""Submission Book Recommendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nwzE1crRFjyVe3HXwaMtzvN28K7pwmU2

##### Nama: Nurul Fatimah
##### Submission: Recommendation System

###### Import Data
"""

# Mengimport library pandas
import pandas as pd

# Mengimport modul drive untuk akses ke google drive
from google.colab import drive

# Mengakses Google Drive
drive.mount('/content/drive')

# Membuat file_path yang akan diakses
books = '/content/drive/My Drive/dataset/book/Books.csv'
ratings = '/content/drive/My Drive/dataset/book/Ratings.csv'
users = '/content/drive/My Drive/dataset/book/Users.csv'

"""###### Membaca dan Menampilkan Data"""

# Membaca file path buku
df_books = pd.read_csv(books)

# Menampilkan data buku
df_books

"""Penjelasan dari setiap column di book :
- ISBN: Nomor Standar Buku Internasional yang unik untuk setiap buku. Ini adalah kunci utama untuk mengidentifikasi buku.
- Book-Title: Judul buku.
- Book-Author: Nama penulis buku.
- Year-Of-Publication: Tahun publikasi buku.
- Publisher: Penerbit buku.
- Image-URL-S: URL untuk gambar sampul buku dengan ukuran kecil.
- Image-URL-M: URL untuk gambar sampul buku dengan ukuran sedang.
- Image-URL-L: URL untuk gambar sampul buku dengan ukuran besar.
"""

#Membaca file path rating
df_ratings = pd.read_csv(ratings)

#Menampilkan data rating
df_ratings

"""Penjelasan dari setiap column di ratings:
- User-ID: ID unik untuk setiap pengguna. Ini berfungsi sebagai kunci utama untuk mengidentifikasi pengguna.
- ISBN: Merujuk ke ISBN dalam tabel buku, menghubungkan penilaian dengan buku yang spesifik.
- Book-Rating: Nilai atau rating yang diberikan oleh pengguna untuk buku tersebut, biasanya dalam skala 1 hingga 10.
"""

# Membaca file path pengguna
df_users = pd.read_csv(users)

# Menampilkan data pengguna
df_users

"""Penjelasan column pada users:
- User-ID: ID unik untuk setiap pengguna, yang juga digunakan dalam tabel ratings untuk mengidentifikasi siapa yang memberi rating.
- Location: Lokasi geografis pengguna, biasanya berupa kota, negara bagian, dan negara.
- Age: Usia pengguna.

###### Exploratory Data Analysis

* Melihat Informasi Data
"""

# Informasi data
print('='*19)
print('Informasi Data Buku')
print('='*19)
df_books.info()
print('\n')
print('='*21)
print('Informasi Data Rating')
print('='*21)
df_ratings.info()
print('\n')
print('='*23)
print('Informasi Data Pengguna')
print('='*23)
df_users.info()

"""Dataset ini terdiri dari tiga tabel dengan jumlah data dan tipe data sebagai berikut:

1. **Data Buku**: Terdiri dari 271,360 entri, semua kolom bertipe `object` (string).
   
2. **Data Rating**: Memiliki 1,149,780 entri, dengan dua kolom bertipe `int64` (`User-ID` dan `Book-Rating`) dan satu kolom bertipe `object` (`ISBN`).

3. **Data Pengguna**: Terdiri dari 278,858 entri, dengan kolom `User-ID` bertipe `int64`, `Location` bertipe `object`, dan `Age` bertipe `float64`.

* Melihat Statistik Data
"""

# Melihat statistik data buku
print("Statistik deskriptif dari data buku: ")
df_books.describe(include='all')

"""Statistik deskriptif dari data buku menunjukkan bahwa dataset ini terdiri dari 271,360 entri unik untuk ISBN, judul buku, dan URL gambar sampul (baik ukuran kecil, sedang, maupun besar). Terdapat 242,135 judul buku unik dan 102,022 penulis unik. Tahun publikasi paling sering adalah tahun 2002 dengan frekuensi 13,903 buku, sementara penerbit yang paling banyak terdaftar adalah Harlequin, yang muncul sebanyak 7,535 kali. Beberapa ISBN dan gambar sampul buku memiliki duplikasi, dengan frekuensi tertinggi adalah 2. Buku dengan judul "Selected Poems" oleh Agatha Christie adalah yang paling sering muncul, sebanyak 27 kali dalam dataset."""

# Melihat statistik data rating
print("\nStatistik deskriptif dari data rating: ")
df_ratings.describe(include='all')

"""Statistik deskriptif dari data rating menunjukkan bahwa dataset ini terdiri dari 1,149,780 entri rating. Kolom **User-ID** memiliki rata-rata nilai sekitar 140,386, dengan rentang dari 2 hingga 278,854. Kolom **ISBN** mencatat 340,556 ISBN unik, dengan ISBN "0971880107" muncul paling sering, yaitu sebanyak 2,502 kali. **Book-Rating** yang diberikan oleh pengguna berkisar dari 0 hingga 10, dengan nilai rata-rata sekitar 2.87 dan standar deviasi 3.85. Sebagian besar buku memiliki rating 0, dengan nilai kuartil pertama, kedua (median), dan ketiga masing-masing 0, 0, dan 7."""

# Melihat statistik data pengguna
print("\nStatistik deskriptif dari data pengguna: ")
df_users.describe(include='all')

"""Statistik deskriptif dari data pengguna menunjukkan bahwa dataset ini terdiri dari 278,858 entri pengguna unik. Kolom **Location** mencatat 57,339 lokasi unik, dengan "london, england, united kingdom" sebagai lokasi yang paling sering muncul, yaitu sebanyak 2,506 kali. Kolom **Age** memiliki data untuk 168,096 pengguna, dengan usia rata-rata sekitar 34.75 tahun dan standar deviasi 14.43 tahun. Usia pengguna berkisar dari 0 hingga 244 tahun, dengan nilai kuartil pertama, kedua (median), dan ketiga masing-masing 24, 32, dan 44 tahun. Kolom **User-ID** bervariasi dari 1 hingga 278,858, dengan rata-rata sekitar 139,429.5.

* Cek Missing Value
"""

# Cek missing value dalam data buku
print('Cek missing value dalam data buku: ')
df_books.isnull().sum()

"""Terdapat nilai kosong dalam column Book-Author sebanyak 2, Publisher sebanyak 2, dan Image-URL-L sebanyak 3 raw."""

# Cek missing value dalam data rating
print('Cek missing value dalam data rating: ')
df_ratings.isnull().sum()

# Cek missing value dalam data pengguna
print('Cek missing value dalam data pengguna: ')
df_users.isnull().sum()

"""Terdapat nilai kosong pada column Age sebanyak 110762.

* Cek Duplikat
"""

# Cek data duplikat dalam data buku
 print('Cek data duplikat dalam data buku: ')
 df_books.duplicated().sum()

# Cek data duplikat dalam data rating
 print('Cek data duplikat dalam data rating: ')
 df_ratings.duplicated().sum()

# Cek data duplikat dalam data buku
 print('Cek data duplikat dalam data pengguna: ')
 df_users.duplicated().sum()

"""###### Data Preprocessing

* Mengetahui Jumlah Rating
"""

books_rating = df_ratings.merge(df_books, on='ISBN', how='left')
books_rating

"""Merge Data: Menggabungkan dua DataFrame, yaitu df_ratings dan df_books, berdasarkan kolom ISBN.

* Cek Missing Value books_rating
"""

books_rating.isnull().sum()

"""###### Data Preparation

* Membersihkan Missing Value
"""

books_rating_clean = books_rating.dropna()
books_rating_clean

"""* Mengecek Kembali Missing Value"""

books_rating_clean.isnull().sum()

"""* Mengecek Duplikat books_rating"""

books_rating_clean.duplicated().sum()

"""* Menghitung Jumlah Rating tiap Buku"""

jml_rate = books_rating_clean.groupby('Book-Title').count()['Book-Rating'].reset_index()
jml_rate.rename(columns={'Book-Rating':'Num_Ratings'}, inplace=True)
jml_rate

"""Memberikan informasi tentang seberapa banyak rating yang diberikan untuk masing-masing buku, membantu dalam analisis popularitas dan kualitas buku berdasarkan ulasan pengguna."""

avg_rate = books_rating_clean.groupby('Book-Title')['Book-Rating'].mean().reset_index()
avg_rate.rename(columns={'Book-Rating':'Avg_Rating'}, inplace=True)
avg_rate

"""Memberikan informasi tentang rata-rata rating yang diberikan untuk masing-masing buku, yang berguna untuk analisis kualitas buku berdasarkan ulasan pengguna."""

df_popular = jml_rate.merge(avg_rate, on='Book-Title')
df_popular

"""Kode diatas untuk menggabungkan jumlah rating dan rat-rata rating"""

df_popular = df_popular[df_popular['Num_Ratings']>250].sort_values('Avg_Rating', ascending=False).head(50)
df_popular

"""Menampilkan 50 buku yang paling populer dan memiliki rating tertinggi berdasarkan jumlah rating yang diberikan, memberikan gambaran tentang buku-buku terbaik menurut ulasan pengguna."""

books_fix = df_books.drop_duplicates('Book-Title')

df_books_popular = df_popular.merge(books_fix, on='Book-Title', how='left')
df_books_popular

df_books_popular.info()

final_popular = df_books_popular[['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher', 'Image-URL-L', 'Num_Ratings', 'Avg_Rating']]

"""* Top 50 Buku Terpopuler"""

final_popular

"""###### Model Development dengan Collaborative Filtering"""

user_rating = books_rating.groupby('User-ID').count()['Book-Rating']
check_reader = user_rating > 200
experienced_user = user_rating[check_reader].index

"""- user_rating: Menghitung jumlah rating yang diberikan oleh setiap pengguna (User-ID).
- check_reader: Menentukan pengguna yang telah memberikan lebih dari 200 rating.
- experienced_user: Mendapatkan ID pengguna yang memenuhi syarat tersebut.
"""

rating_filter = books_rating[books_rating['User-ID'].isin(experienced_user)]
rating_filter

"""rating_filter: Mengambil rating buku hanya dari pengguna yang dianggap berpengalaman."""

book_ratings_count = rating_filter.groupby('Book-Title').count()['Book-Rating']
check_book = book_ratings_count >= 50
popular_books = book_ratings_count[check_book].index

"""- book_ratings_count: Menghitung jumlah rating untuk setiap buku.
- check_book: Menentukan buku yang telah mendapatkan 50 atau lebih rating.
- popular_books: Mendapatkan judul buku yang memenuhi syarat tersebut.
"""

result_rate = rating_filter[rating_filter['Book-Title'].isin(popular_books)]
result_rate

"""result_rate: Mengambil rating hanya untuk buku yang termasuk dalam kategori buku populer."""

pivot_book_ratings = result_rate.pivot_table(index='Book-Title', columns='User-ID', values='Book-Rating')
pivot_book_ratings

pivot_book_ratings.fillna(0, inplace=True)
pivot_book_ratings

"""- pivot_book_ratings: Membuat tabel pivot dengan judul buku sebagai indeks, ID pengguna sebagai kolom, dan rating buku sebagai nilai.
- fillna(0): Mengisi nilai kosong dengan 0.
"""

from sklearn.metrics.pairwise import cosine_similarity
similarity_score = cosine_similarity(pivot_book_ratings)
similarity_score.shape

"""similarity_score: Menghitung kemiripan antara buku menggunakan cosine similarity. Hasilnya adalah matriks kemiripan dengan ukuran yang sama dengan jumlah buku."""

import numpy as np

def recommendation(book_name):
    # Temukan index buku yang diminta dalam pivot_book_ratings
    index = np.where(pivot_book_ratings.index == book_name)[0][0]

    # Menghitung skor kemiripan dan memilih 5 item teratas, kecuali item itu sendiri
    similar_item = sorted(list(enumerate(similarity_score[index])), key=lambda x: x[1], reverse=True)[1:6]

    # Menyimpan hasil rekomendasi dalam list
    recommendations = []
    for i in similar_item:
        # Ambil data buku yang sesuai dari books_fix
        temp_df = books_fix[books_fix['Book-Title'] == pivot_book_ratings.index[i[0]]]
        for _, row in temp_df.iterrows():
            recommendations.append({
                'Book-Title': row['Book-Title'],
                'Book-Author': row['Book-Author'],
                'Book-Publisher': row['Publisher']
            })

    # Membuat DataFrame dari hasil rekomendasi
    recommendations_df = pd.DataFrame(recommendations)

    return recommendations_df

"""- recommendation(book_name): Fungsi yang memberikan rekomendasi buku serupa berdasarkan nama buku yang diberikan.
  - index: Menentukan indeks buku yang dimaksud dalam tabel pivot.
  - similar_item: Mendapatkan buku-buku yang paling mirip dengan buku yang dimaksud berdasarkan kemiripan cosine.
  - data: Mengumpulkan data judul dan penulis buku yang direkomendasikan.
"""

result_df = recommendation('Year of Wonders')
result_df

"""Output dari kode diatas akan menampilkan 5 rekomendasi buku sesuai syarat yang ditentukan

###### Evaluation

Metrik evaluasi yang digunakan adalah Mean Average Precision (MAP). MAP (Mean Average Precision) mengukur kinerja sistem rekomendasi dengan menghitung rata-rata dari precision di berbagai posisi relevan dalam daftar rekomendasi. Precision diukur pada setiap posisi relevan dalam daftar rekomendasi dan kemudian dirata-ratakan untuk seluruh item.
"""

def evaluate_map(recommended_books, threshold, k):
    # Daftar untuk menyimpan precision pada posisi relevan
    avg_precision_list = []

    # Grup data berdasarkan item untuk evaluasi
    grouped = recommended_books.groupby('Book-Title')

    for title, group in grouped:
        relevant_items = group['Book-Rating'] > threshold
        retrieved = np.sum(relevant_items)

        if retrieved == 0:
            continue

        precision_at_i = [np.sum(relevant_items[:i+1]) / (i+1) for i in range(len(relevant_items))]
        avg_precision = np.sum(precision_at_i * relevant_items) / np.sum(relevant_items)
        avg_precision_list.append(avg_precision)

    map_score = np.mean(avg_precision_list) if avg_precision_list else 0
    return map_score

# Contoh penggunaan
k = 10
threshold = 2
map_score = evaluate_map(rating_filter, threshold, k)
print(f'The MAP score of the recommendation system is {map_score:.2%}')

"""- evaluate_map(recommended_books, threshold, k): Fungsi ini menghitung Mean Average Precision (MAP) dari buku yang direkomendasikan. Parameter:
recommended_books: Dataframe yang berisi buku-buku yang direkomendasikan dengan ratingnya.
threshold: Nilai rating yang dianggap relevan.
k: Jumlah rekomendasi yang diambil (tidak digunakan secara eksplisit dalam kode, tetapi dapat mempengaruhi pengaturan data)

- avg_precision_list = []: Daftar untuk menyimpan nilai precision rata-rata untuk setiap buku.

- grouped = recommended_books.groupby('Book-Title'): Mengelompokkan data berdasarkan judul buku (Book-Title), sehingga setiap kelompok berisi rating yang diberikan untuk buku tertentu.

- for title, group in grouped:: Iterasi melalui setiap buku dan kelompoknya.
relevant_items = group['Book-Rating'] > threshold: Menentukan item yang relevan berdasarkan threshold. Ini menghasilkan array boolean yang menunjukkan apakah rating suatu buku lebih besar dari threshold.
retrieved = np.sum(relevant_items): Menghitung jumlah item relevan.
if retrieved == 0: continue: Jika tidak ada item relevan, lanjutkan ke buku berikutnya.
precision_at_i = [np.sum(relevant_items[:i+1]) / (i+1) for i in range(len(relevant_items))]: Menghitung precision pada setiap posisi i. Precision pada posisi i adalah proporsi item relevan yang ditemukan sampai posisi i.
avg_precision = np.sum(precision_at_i * relevant_items) / np.sum(relevant_items): Menghitung rata-rata precision untuk buku tersebut, dengan mempertimbangkan hanya posisi relevan.

- map_score = np.mean(avg_precision_list) if avg_precision_list else 0: Menghitung MAP sebagai rata-rata dari precision rata-rata untuk semua buku. Jika tidak ada buku, MAP diatur ke 0.

- map_score = evaluate_map(rating_filter, threshold, k): Menghitung MAP berdasarkan data rekomendasi (rating_filter), threshold, dan jumlah rekomendasi k.
print(f'The MAP score of the recommendation system is {map_score:.2%}'): Menampilkan hasil MAP sebagai persentase.
"""